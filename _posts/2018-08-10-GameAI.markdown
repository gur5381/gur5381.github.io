---
layout: post
title:  "Game AI Algorithms (1)"
date:   2018-08-10 04:00:00 +0900
author: Yangyangii
categories: GameAI
tags:	GameAI
cover:  "/assets/instacode.png"
---

## Introduction
+	알파고가 나오면서 강화학습이 유명해졌지만, 그 외에도 많은 Game AI 알고리즘들이 존재한다.
+	이 포스팅에서는 대표적인 Search based 알고리즘에 대해 알아본다(알파고 또한 강화학습과 함께 사용되었다)
+	고려대학교의 에브리코딩 튜터자료와 위키피디아를 참고하였습니다.


## Rule-based Algorithm
+	**개념:** 요즘 머신러닝 알고리즘 외에 사람이 직접 프로그래밍한 알고리즘을 뭉뚱그려 이야기하는데, 임의의 input이 들어왔을 때 원하는 output이 나오도록 우리가 Rule을 만들어주는 것이라고 생각하면 되겠다 (우리는 이미 프로그래밍을 할 때 조건문 등을 이용하여 하고 있다)
+	**장점:** 완벽한 Rule을 만들면(일어날 수 있는 조건을 모두 고려한 프로그래밍을하면) output 또한 완벽하다.
+	**단점:** 사람이 생각하고 프로그래밍할 수 있는 한계를 넘어서면(익히 알듯이 Real world에서는 그런 요소들이 무수히 많다) 대처할 수 없는 상황들이 생긴다.
+	**결론:** 우리는 대부분의 임의의 상황에 대하여 모두 대처하는 완벽한 알고리즘을 직접 coding할 수 없다. 따라서 컴퓨터가 계산하여 대처하도록 만들되, 확률적으로 확실한 것들과 프로그래머가 반드시 개입해야하는 부분에 대해 개입하자.


## Search-based Algorithm
+	**개념:** 다음에 가능한 Action들에 대해서 미리 탐색을 해서 미래의 조건까지 고려하는 알고리즘이다. 즉, 특정 조건들에 대해 Search를 하는 적은 Rule을 우리가 정해주고 미래에 가능한 Action들을 컴퓨터가 탐색한 후에 현재의 Action을 선택한다.
+	**장점:** 미래에 일어날 다양한 State들에 따른 Action을 미리 계산하여 대비할 수 있다.
+	**단점:** 최적화 혹은 개선된 알고리즘에 따라 다르겠지만 일반적으로 얼마나 탐색하는가에 따라 Computation을 많이 필요로 한다.
+	##	Minimax
	+	minimax 알고리즘의 원리는 아주 간단하다. search tree를 만들었을 때 점수를 측정하고, 점수는 나를 기준으로 높으면 좋고 낮으면 나쁘기 때문에, 상대방은 나에게 나쁜 낮은 점수를 선택하고, 나는 높은 점수를 선택한다는 가정하에 terminal node부터 하나씩 parent node로 min 혹은 max 점수를 올려보낸다. 최종적으로 root node에 올라온 점수에 해당하는 path를 선택한다.
	+	원리는 간단하지만 위 설명에서 빠트린 부분이 있다. 점수를 어떻게 측정하냐는 것인데, 이를 heuristic evaluation이라고 하고 알고리즘 구현에서 핵심이 되는 부분이라 볼 수 있다.
	+	그래서 그걸 어떻게 측정하냐고? 여러 상황들에 대해서 점수(유/불리)를 프로그래머가 직접 Rule을 만들어 측정하고 노드에게 부여하면 된다(그렇다 멀리 돌아왔으나 결국 Rule-based의 미래형 버전이다)
	+	Depth에 따라 미래의 Action을 얼마나 볼지를 정하게 되며, 클수록 computation은 exponential하게 증가한다.
	
{% highlight python %}
function minimax(node, depth, maximizingPlayer) is
    if depth = 0 or node is a terminal node then
        return the heuristic value of node
    if maximizingPlayer then
        value := −∞
        for each child of node do
            value := max(value, minimax(child, depth − 1, FALSE))
        return value
    else (* minimizing player *)
        value := +∞
        for each child of node do
            value := min(value, minimax(child, depth − 1, TRUE))
        return value
{% endhighlight %}

+	## Alpha-beta prunning
	+	일명 가지치기라 불리운다. 필요없는 계산은 제외시키는 minimax를 개선한 알고리즘
	+	생각해보면 트리에서 특정 노드들을 계산에서 제외시키는 방법은 여러가지가 있을 수 있다. 그럼 alpha-beta prunning은 어떤 특징을 갖는가?
	+	내 자신의 level에서 계산할때 alpha는 child node들을 순차적으로 탐색하며 max를 갱신할텐데 갱신될때마다의 max값이 alpha이다. beta는 parent node의 값(이전의 child node들에 의해 update 되어있음)인데 alpha가 beta보다 작은 경우가 나오면, 나머지 child node에 대해 고려하지 않는다.
	+	상대방의 level에서는 위의 반대로 하면 된다. 즉, 각 턴의 level에서 min과 max를 생각하여 alpha와 beta를 비교하여 필요없는 계산을 제외시킨다.

{% highlight python %}
function alphabeta(node, depth, α, β, maximizingPlayer) is
    if depth = 0 or node is a terminal node then
        return the heuristic value of node
    if maximizingPlayer then
        value := −∞
        for each child of node do
            value := max(value, alphabeta(child, depth − 1, α, β, FALSE))
            α := max(α, value)
            if α ≥ β then
                break (* β cut-off *)
        return value
    else
        value := +∞
        for each child of node do
            value := min(value, alphabeta(child, depth − 1, α, β, TRUE))
            β := min(β, value)
            if α ≥ β then
                break (* α cut-off *)
        return value
{% endhighlight %}


## References
+   <em>[Everycoding](https://everycoding.net/tutor/38)</em>
+	<em>[Minimax(Wikipedia)](https://en.wikipedia.org/wiki/Minimax)</em>
+	<em>[Alpha-beta prunning](https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning)</em>